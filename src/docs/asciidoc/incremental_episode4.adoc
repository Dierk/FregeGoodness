[[incremental_episode4]]

== Episode Four: Going safely parallel

So far we have incrementally developed

* a general solution for playing board games with mutual moves,
* a specialization for the rules of tic-tac-toe, and
* an extra _forecast_ feature to see how the computer thinks that the game will develop.

All that code turns out to be _purely functional_.
There is _not a single assignment_ in the code, _no state_ that needs to get updated,
and therefore also no shared mutable state that could impose any issues when going parallel.
Furthermore, there are _no side effects_ in the code.

Since we have just written the code, we remember that we have not written anything impure.
But we can even be sure about the purity characteristic without any prior knowledge of the 
implementation: _the type system tells us so_!
 
=== Map is pure
 
And this comes so: the main entry point to our solution is a call to the `map` function and
the type signature of _map_ is

.The signature of _map_
[source,haskell]
----
map :: ( α -> β ) -> [α] -> [β]
----

Let's start with the first argument `( α -> β )`.

It means that the first argument to `map` is a function from any unconstrained type `α`
to any unconstrained type `β`. Let's call that function _f_.
The `map` function applies its argument function _f_ to all elements of a list of
`α` values to produce a list of `β` values, not knowing any specifics about _f_.

In our case _f_ happens to be `(probe lookahead)`. We are _probing_ each board, looking
no further than the given _lookahead_ where probing can be either the valuation of the
board or the detection of the forecast.

Mapping any function _f_ over a list of `α` values cannot possibly perform a side effect.
The closest possibility would be a specific function _f_ that returns an IO action as type `β`.
But even in that case, the IO action is only _created_, not _performed_.
No implementation of `map` would ever be able to perform such an action since `map` cannot assume
_anything_ about `β` - particularly it cannot assume that `β` is an action.

In other words: *the signature of `map` asserts purity of `map f`* and the
Frege *type system* enforces this _down the whole call chain_!
We do not have to go back and check the code ourselves for possible purity breaches
nor can any maintainer accidentally undermine our foundation through subsequent changes.

Now, what happens if we go parallel and use `mapP` (the parallel version of `map`)
instead of `map`? Here is the type signature of `mapP`:

.The signature of _mapP_
----
mapP :: ( α -> β ) -> [α] -> [β]
----

That is *exactly the same*! The whole line of argumentation about purity of `map f` equally applies to `mapP f`!
....
*Let that sink in for a minute.*
....
=== Parallelism as an increment

With Frege, we can again apply a _non-intrusive increment_: from _sequential_ to _parallel_ execution in an absolutely safe manner.
Purity and its handling in the type system makes that possible.
In all other popular JVM languages this would have been an *_immensely_* intrusive change (even if old code was not edited at all -
changing its mode of operation is intrusive) with a _huge_ potential to introduce hard-to-detect errors.

And again, we were able to apply this non-intrusive increment _without having planned for it_.
We just did what is usual in Frege and it turned out to just fit.

We can almost always safely go from _map_ to _mapP_.

There are two _considerations_, however, that we should apply before blindly making all calls to _map_ parallel:

*1) Granularity*
We applied parallel execution on the top-most layer of the evaluation only, not down to all splits of possible boards.
That is a usual performance concern for data-parallel code where we weigh the relative overhead of thread scheduling
against the size of the unit of work.

*2) Infinite data structures*
Parallel execution makes usually no sense to work _lazily_ since new threads should start working eagerly to have the
result ready when requested. But that approach would never finish when applied to _infinite_ data structures.

But those considerations are fully inside our mental context when applying our increment.
We are in the position to decide about granularity and we know that _possibleMoves_ is a finite list.
It is a reasoning that is local to one single increment.

.For the geeks
****
The parallel execution in `mapP` would have no effect at all if the usual lazy evaluation strategy was applied.
Each parallel function application would return immediately, leaving an unevaluated expression behind - for later, lazy
execution. +
The implementation of _mapP_ avoids this trap by enforcing the
https://wiki.haskell.org/Weak_head_normal_form[weak-head-normal-form (WHNF)] of each element in the result list.
****

My personal experience was very strange when I applied parallelism to the tic tac toe game.
I went from _map_ to _mapP_,  let the code run, and enjoyed the speedup.
Then I fell back into my old habit of paranoid concurrency thinking: *_what could possibly go wrong_*?

And for the first time ever in such a situation, I couldn't think of any possible issue.

=== References
[horizontal]
John Hughes::
http://www.cs.kent.ac.uk/people/staff/dat/miranda/whyfp90.pdf[Why functional programming matters]

Tic Tac Toe::
https://klondike.canoo.com/tictactoe/game[live game],
https://github.com/Dierk/fregePluginApp/blob/game_only/src/frege/fregepluginapp/Minimax.fr[full Frege source code],
https://github.com/Dierk/fregePluginApp/blob/game_only/grails-app/controllers/fregepluginapp/FooController.groovy[web integration code]
